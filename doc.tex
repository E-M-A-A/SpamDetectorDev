\documentclass{report} 

\usepackage{amsmath} % \usepackage is a command that allows you to add functionality to your LaTeX code
\usepackage{graphfig, subfig}
\usepackage{graphicx}
\usepackage{hyperref}

\usepackage{caption}
\captionsetup{labelformat=empty,textfont=sl}

\usepackage[Glenn]{fncychap}
\title{Storytelling} % Sets article title
\author{Emmanuele Virginio Coppola, Muriel Rossi, Alessandro Marigliano} % Sets authors name

\begin{document} % All begin commands must be paired with an end command somewhere 
    \maketitle % creates title using information in preamble (title, author, date)  $\downarrow$   \date{\today} % Sets date for date compiled

    \tableofcontents
    \chapter{Introduzione} % creates a chapter
    
    La pubblicità invasiva si rivela essere sempre maggiormente un problema asfissiante all'interno del mondo dei socialnetwork. Nonostante siano state sviluppate diverse tecniche
    allo scopo di domare questa piaga, alcune inserzioni riescono tuttavia a sfuggirne, intasando interfacce dedicate all'informazione ed 
    all'intrattenimento, che subiscono così una svalutazione, venendo "soffocate".
    

    \textbf{Legge di Reed: il valore di una rete sociale è direttamente proporzionale ad una funzione esponenziale in N:}
    \begin{equation} % Creates an equation environment and is compiled as math
        V=a*N+b*N^2 + c*2^n
    \end{equation}
    

    La legge sopra citata, descrive come il valore di una rete, formata da interazioni ed intrecci, cresca esponenzialmente con la dimensione di quest'ultima. (1.1).
    In particolare, nel caso di Internet, si osserva come il suo valore tenda a crescere in modo esponenziale se associato a gruppi con interessi
     comuni, che condividono idee, interessi ed obiettivi.
    Da questo se ne deduce come invece, avvisi pubblicitari, spam ed altra "informazione spazzatura", possano far decadere il valore di una rete.
    
    Questo progetto si prefigge lo scopo di manutenere una piattaforma libera dal bombardamento pubblicitario e dare modo all'utenza di potersi esprimere liberamente
    all'interno di questa, distaccandosi dall'ansia e dalla continua distrazione provocata dal chiasso delle inserzioni.
    \chapter{Descrizione dell'agente}
    Allo scopo di realizzare questo progetto, è stato introdotto un agente intelligente, sarà lui ad occuparsi della supervisione della piattaforma, indagando fra i 
    commenti relativi alle varie pubblicazioni.
    \section{Obiettivi}
    L'obiettivo dell'agente sarà quello di effettuare un'analisi giornaliera dei commenti relativi ad ogni pubblicazione effettuata dagli utenti della piattaforma.
    Il testo dei vari commenti verrà preso in analisi e, dopo essere stato adeguatamente "pulito", verrà sottoposto all'agente, che sarà in grado di riconoscere se il 
    testo è conforme alle norme della piattaforma (ovvero se non è sospettato come spam). \newline
    In caso negativo, l'autore del commento verrà segnalato alla piattaforma, che provvederà ad eliminarlo da quest'ultima, assieme a tutto il materiale da lui pubblicato.

    \section{Specifiche PEAS}
    Le specifiche PEAS rappresentano diverse proprietà tramite cui è possibile descrivere l'agente. \newline

    \begin{itemize}
        \item 
        {\bfseries P = Performance.} 
        L'agente verrà valutato in base alla percentuale di commenti spam categorizzati correttamente.
        \item 
        {\bfseries E = Environment.} L'agente nel caso in questione lavorerà su query di commenti relativi ai post pubblicati sul Social Network, 
        navigando fra i commenti degli utenti.\newline
        Nello specifico l'ambiente sarà:
            \begin{itemize}
                \item {\bfseries Completamente Osservabile}, in ogni momento l'agente ha completa conoscenza
                dell'ambiente in cui lavora, ovvero la collezione di commenti;
                \item {\bfseries Deterministico}, l'ambiente verrà modificato in base alla decisione dell'agente, 
                ovvero verranno rimossi gli utenti che l'agente deciderà di segnalare;
                \item {\bfseries Episodico}, l'agente viene attivato ad intervalli temporali di 24h. La scelta che compirà l'agente in un singolo episodio dipenderà dall'episodio stesso;
                \item {\bfseries Statico}, mentre analizza la query di commenti, l'ambiente rimane invariato;
                \item {\bfseries Discreto}, l'ambiente infatti fornisce un insieme di parole finite per ogni commento. L'agente
                dovrà decidere orientandosi fra queste ed avrà azioni limitate (segnalare l'utente o non farlo); 
                \item {\bfseries Singolo}, l'agente che opererà sarà singolo.
            \end{itemize}
          
        \item 
        {\bfseries A = Actuators.} L'agente potrà effettuare il suo giudizio stilando una lista di email relative ai proprietari dei commenti che sono stati sospetatti di spam.
        \item 
        {\bfseries S = Sensors.} Il modo in cui l'agente riceverà gli input percettivi sarà tramite il dataset di commenti.I sensori attraverso cui riceve gli input percettivi.
        
    \end{itemize}
    

    

                        


   
    \chapter{Raccolta, analisi e preprocessing dei dati}
    L'agente, prima di essere inserito all'interno della piattaforma, è stato "allenato" su un dataset, scelto accuratamente per massimizzare la somiglianza ai dati con cui dovrà lavorare 
    durante la sua effettiva applicazione. 
    \section{Scelta del dataset}
    Il dataset preso in esame raccoglie diversi commenti relativi a video sulla piattaforma di streaming YouTube. 
    Consiste in un insieme di tuple contenenti le colonne:
    \begin{itemize}
        \item Identificativo del commento
        \item "AUTHOR", l'autore
        \item "DATE", la data in cui è stato pubblicato
        \item "CONTENT", il suo contenuto
        \item "CLASS", contenente un numero (0 o 1), che individua il commento come ham o spam rispettivamente.
    \end{itemize}
    \begin{figure}
        \centering
        \includegraphics[width = 0.8\textwidth]{immagini/datasetExample.png}
        \caption{Immagine del dataset iniziale}

    \end{figure}


    E' stato scelto questo dataset in quanto i commenti susseguenti i video si avvicinavano estremamente alle possibili tuple di commenti
    di un reale caso applicativo all'interno della piattaforma.
    Inoltre presentava un'amplia gamma di instanze, così da permettere un buon addestramento dell'agente.
    Il dataset è stato trovato a questo indirizzo: \newline 
    \href{https://www.kaggle.com/datasets/lakshmi25npathi/images}{https://www.kaggle.com/datasets/lakshmi25npathi/images}.
    
    \section{Pulizia del dataset}
    Il dataset, nonostante fosse già estremamente adeguato alle esigenze dell'agente, durante la fase di feature extraction, 
    è stato privato della colonne identificativo del commento, "AUTHOR", "DATE", in quanto avrebbero potuto falsare i risultati dell'agente, 
    perchè non inerenti all'identificazione di un commento spam.
    L'operazione di pulizia si è poi composta delle seguenti fasi: 
    \begin{itemize}
        \item {\bfseries Conversione da uppercase a lowercase}, tutte le lettere in maiuscolo sono state convertite in minuscolo;
        \item {\bfseries Rimozione degli invii}, tutti i "break" sono stati rimossi;
        \item {\bfseries Rimozione della punteggiatura}, è stata eliminata ongi forma di punteggiatura;
        \item {\bfseries Trascrizione dei link}, i link sono stati convertiti in singole parole;
        \item {\bfseries Rimozione degli spazi}, gli spazi consecutivi, ovvero in  quantità maggiore di 1, sono stati rimossi;
        \item {\bfseries Eliminazione lettere ripetute}, lettere identiche, ripetute in quantità maggiore di 2, sono state rimosse;
        \item {\bfseries Correzzione delle parole}, parole non presenti all'interno del vocabolario (scritte quindi in maniera errata oppure in tempi diversi dall'infinito), sono state sottoposte 
        ad un'algoritmo di pattern matching. La funzione nello specifico, cerca inizialmente il match con parole di uso più comune. Il caso in cui
        la parola presenti più matches, viene scelta la prima parola ad essere stata individuata;
        \item {\bfseries Eliminazione delle "stopwords"}, tutte le parole che rientravano nel dizionario delle stopwords (ovvero parole che non aggiungono alcuna informazione) 
        sono state eliminate;
        \item {\bfseries Eliminazione valori nulli}, tutti i testi che, dopo aver superato questa scrematura, risultavano infine vuoti, sono stati eliminati.

    \end{itemize}

    \begin{figure}
        \centering
        \includegraphics[width = 0.9\textwidth]{immagini/datasetPulito.png}
        \caption{Immagine del dataset dopo le operazioni di pulizia}

    \end{figure}

    \section{Bilanciamento del dataset}
    Questo è il grafico della suddivisione fra spam ed ham nei vari dataset.
    \begin{figure}
        \centering
        \includegraphics[width = 0.9\textwidth]{immagini/DatasetSeparati.png}
    \end{figure}

    Questo è il grafico della suddivisione fra spam ed ham in tutti i dataset.

    \begin{figure}[h]
        \centering
        \includegraphics[width = 0.9\textwidth]{immagini/DatasetUnico.png}
    \end{figure}


    drgftghgn
    \chapter{Creazione agente}
    Dopo aver definito gli obiettivi dell'agente, le sue specifiche, l'ambiente in cui avrebbe lavorato, ed il suo dataset, si è deciso come andava effettivamente costruito l'agente.
    L'agente dovrà stimare se un commento è un avviso pubblicitario o meno con il solo aiuto delle parole presenti nel commento. Inizialmente è stato sottoposto all'agente 
    un dataset di commenti, ognuno dei quali era contrassegnato da un target "1", se lo specifico commento era spam, o contrassegnato da target "0" se il commento era ham.
    E' quindi stata creata una tabella dove venivano individuate, per ciascun commento,
    la frequenza con la quale alcune parole ricorrevano. In questo caso ci è venuto in aiuto l'algoritmo {\bfseries Naive Bayes}:
    \newline
    \begin{equation}\label{bho}
        { p(B|A)  p(A)\over p(B)}
    \end{equation}
    \newline
    che, nel nostro caso, si traduce in:
    \newline
    \begin{equation}\label{bho2}
        p(spam|commento) = { p(commento|spam)  p(spam)\over p(commento)}
    \end{equation}
    \newline
    ovvero, la probabilità che un commento sia spam, è uguale alla probabilità che le parole del commento compaiano in un commento spam, dato che è spam, per la probabilità 
    che il commento sia spam, diviso la probabilità che queste parole compaiano nel commento.
\end{document}